{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Search and Sample Return by Mouhyemen Khan\n",
    "---\n",
    "\n",
    "\n",
    "## 1. Project Summary\n",
    "\n",
    "### 1.1 Objectives:\n",
    "* Map atleast 40% of the map\n",
    "* Atleast 60% fidelity\n",
    "* Locate at least one rock sample\n",
    "\n",
    "### 1.2 Outcomes:\n",
    "* Mapped 98% of the map\n",
    "* With 70% fidelity\n",
    "* Located and picked up all 6 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## 2. Detection of navigable terrain, obstacles, and rock samples\n",
    "\n",
    "### 2.1 Navigable Terrain\n",
    "The image coming in from the Rover's perspective is first warped using OpenCV's perspective transform function. Then a color thresholding filter is applied on the warped image. The result is as follows.\n",
    "[threshed]: ./threshed.png\n",
    "![alt text][threshed]\n",
    "\n",
    "To improve the fidelity, the thresholded figure shown above is not taken as is. Instead, a mask is applied on it to extract only a certain portion of the thresholded-warped figure. The result is shown below.\n",
    "[box_nav]: ./box_nav.png\n",
    "![alt text][box_nav]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4,
     24
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Identify pixels above the threshold\n",
    "Threshold of RGB > 160 does a nice job of identifying ground pixels only\n",
    "'''\n",
    "def color_thresh(img, rgb_thresh=(160, 160, 160)):\n",
    "    # Create an array of zeros same xy size as img, but single channel\n",
    "    color_select = np.zeros_like(img[:, :, 0])\n",
    "    # Require that each pixel be above all three threshold values in RGB\n",
    "    # above_thresh will now contain a boolean array with \"True\"\n",
    "    # where threshold was met\n",
    "    above_thresh = (img[:, :, 0] > rgb_thresh[0]) \\\n",
    "        & (img[:, :, 1] > rgb_thresh[1]) \\\n",
    "        & (img[:, :, 2] > rgb_thresh[2])\n",
    "    # Index the array of zeros with the boolean array and set to 1\n",
    "    color_select[above_thresh] = 1\n",
    "    # Return the binary image\n",
    "    return color_select\n",
    "\n",
    "'''\n",
    "The idea is to limit the amount of navigable terrain to increase fidelity\n",
    "Do a series of erosions and dilations to remove any sharp edges or blobs.\n",
    "Create a rectangular mask that comes out of the robot's POV.\n",
    "Use the mask on the dilated (thresholded) image\n",
    "'''\n",
    "def box_threshed(threshed):\n",
    "    eroded   = cv2.erode(threshed, None, iterations=2)\n",
    "    dilated  = cv2.dilate(eroded, None, iterations=4)\n",
    "\n",
    "    mask_box = np.zeros_like(threshed)\n",
    "    boxHeight, boxWidth = mask_box.shape[0], mask_box.shape[1]\n",
    "    up       = int(boxHeight/2+20)\n",
    "    down  = int(boxHeight)\n",
    "    left     = int(boxWidth/2-80)\n",
    "    right   = int(boxWidth/2+80)\n",
    "    mask_box[up:down, left:right] = 1\n",
    "\n",
    "    final   = cv2.bitwise_and(dilated, dilated, mask = mask_box)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Obstacle outlining\n",
    "The method employed here is to simply outline the navigable terrain detected using contour detection. First, a series of erosions and dilations are performed to remove any edges and blobs. Then contours are detected and outlined.\n",
    "[outline_obstacle]: ./outline_obstacle.png\n",
    "![alt text][outline_obstacle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     6
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Create obstacle map from navigable terrain map.\n",
    "First detect the contours and draw it.\n",
    "Then mask out the interior of the contour.\n",
    "'''\n",
    "def create_obs_map(nav_map):\n",
    "    _,cnts,_ = cv2.findContours(nav_map.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    obs_map = np.zeros_like(nav_map)\n",
    "    cv2.drawContours(obs_map, cnts, -1, (1), 15)\n",
    "    white = nav_map[:,:] > 0\n",
    "    obs_map[white] = 0\n",
    "    return obs_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Rocks detection\n",
    "A simple color filtering is applied on RGB color space to detect the rock samples. The result is shown below.\n",
    "[detect_rock]: ./detect_rock.png\n",
    "![alt text][detect_rock]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function will detect rocks within a certain RGB threshold value.\n",
    "Yellow rocks have a high red and green value with a low blue value.\n",
    "'''\n",
    "def detect_rocks(img, rock_thresh=(110, 110, 60)):\n",
    "    # Create an array of zeros same xy size as img, but single channel\n",
    "    color_select = np.zeros_like(img[:, :, 0])\n",
    "\n",
    "    above_thresh = (img[:, :, 0] > rock_thresh[0]) \\\n",
    "        & (img[:, :, 1] > rock_thresh[1]) \\\n",
    "        & (img[:, :, 2] < rock_thresh[2])\n",
    "    # Index the array of zeros with the boolean array and set to 1\n",
    "    color_select[above_thresh] = 1\n",
    "    # Return the binary image\n",
    "    return color_select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Perception\n",
    "\n",
    "The `perception_step(Rover)` carries out a series of steps and updates the Rover object. The high-level breakdown of `perception_step(Rover)` is the following:\n",
    "\n",
    "### 3.1 Perspective Transform, Navigable Terrain and Obstacle Mapping\n",
    "First, we create our source and destination points that will be used to perform a perspective transform. The warped image is color filtered using `color_thresh()` and masked into a smaller region using the `box_threshed()` function. The `create_obs_map()` function outlines the obstacle region around the navigable region. The resultant is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "# 1) Define source and destination points for perspective transform\n",
    "dst_size, bottom_offset = 5, 6\n",
    "source = np.float32([[14, 140], [301, 140], [200, 96], [118, 96]])\n",
    "destination = np.float32([[image.shape[1] / 2 - dst_size, image.shape[0] - bottom_offset],\n",
    "                          [image.shape[1] / 2 + dst_size, image.shape[0] - bottom_offset],\n",
    "                          [image.shape[1] / 2 + dst_size, image.shape[0] - 2 * dst_size - bottom_offset],\n",
    "                          [image.shape[1] / 2 - dst_size, image.shape[0] - 2 * dst_size - bottom_offset],\n",
    "                          ])\n",
    "\n",
    "# 2) Apply perspective transform\n",
    "warped, mask = perspect_transform(image, source, destination)\n",
    "\n",
    "# 3) Apply color threshold to identify navigable terrain/obstacles/rock samples\n",
    "threshed = color_thresh(warped)\n",
    "threshed = box_threshed(threshed)\n",
    "obs_map  = create_obs_map(threshed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[step1_image]: nav_direction.png\n",
    "![alt text][step1_image]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Updating rover vision image and coordinate transformations\n",
    "\n",
    "Now that we have information on navigable terrain and obstacle region, we update the `Rover.vision_image` attribute. We then convert the pixels of both navigable and obstacle terrains to rover-centric coordinates using `rover_coords()` function. These coordinates are then converted to world coordinates using `pix_to_world()` function. Now that we have information on world centric coordinates, we update the `Rover.worldmap` attribute with navigable and obstacle pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4) Update Rover.vision_image (this will be displayed on left side of screen)\n",
    "Rover.vision_image[:, :, 2] = threshed * 255  # nav terrain color-thresholded binary image\n",
    "Rover.vision_image[:, :, 0] = obs_map * 255   # obstacle color-thresholded binary image\n",
    "\n",
    "# 5) Convert map-image pixel values to rover-centric coords\n",
    "xpix, ypix = rover_coords(threshed)         # array of rover_xy values for nav map\n",
    "obs_xpix, obs_ypix = rover_coords(obs_map)  # array of rover_xy values for obs map\n",
    "\n",
    "# 6) Convert rover-centric pixel values to world coordinates\n",
    "xpos, ypos = Rover.pos[0], Rover.pos[1]  # current x & y position\n",
    "yaw        = Rover.yaw      # current yaw angle\n",
    "scale      = 10\n",
    "world_size = Rover.worldmap.shape[0]  # 200 x 200\n",
    "\n",
    "xworld, yworld = pix_to_world(xpix, ypix, xpos, ypos, yaw, world_size, scale) # navigable xy-world coordinates\n",
    "\n",
    "obs_xworld, obs_yworld = \\\n",
    "pix_to_world(obs_xpix, obs_ypix, xpos, ypos, yaw, world_size, scale)# obstacle xy-world coordinates\n",
    "\n",
    "# 7) Update Rover worldmap (to be displayed on right side of screen)\n",
    "Rover.worldmap[yworld, xworld, 2] += 20  # setting nav terrain to blue\n",
    "Rover.worldmap[obs_yworld, obs_xworld, 0] += 1  # setting obstacles to red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Rock detection\n",
    "\n",
    "Next, we move onto detecting rocks from the Rover's camera's point of view using the `detect_rocks()` function explained above. After that, we check if a rock sample is located but not picked up. If that is the case, then the `Rover.mode` attribute changes to `'orient'` mode.\n",
    "\n",
    "#### Note: `Rover.mode` attributes are explained in more detail under Section #4: Autonomous Navigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 8) Detecting rocks in the map\n",
    "rock_map = detect_rocks(image)\n",
    "\n",
    "# 9) Checking if any rock samples are not collected. \n",
    "# If True, then the Rover goes to 'orient' mode\n",
    "samples_uncollected = Rover.samples_located - Rover.samples_collected\n",
    "if samples_uncollected > 0:\n",
    "        if Rover.orient_flag is 0 and not Rover.picking_up:\n",
    "            Rover.mode = 'orient'\n",
    "            Rover.orient_flag = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following segment of code checks if a rock is indeed detected. If so, then first we need to convert the rock-pixels into rover-centric coordinates and then to world-centric coordinates. `center_rock()` function is used for finding the center of the rock and then displaying it on the worldmap.\n",
    "\n",
    "A desired yaw angle is calculated using the inverse arc2 tangent function. Since the worldmap is inverted along y-axis, a mapping of the desired yaw angle is being computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     7
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def center_rock(rover_rockx, rover_rocky, world_rockx, world_rocky):\n",
    "    rock_dist, rock_angles = to_polar_coords(rover_rockx, rover_rocky)\n",
    "    min_idx = np.argmin(rock_dist)\n",
    "    x_cen = world_rockx[min_idx]\n",
    "    y_cen = world_rocky[min_idx]\n",
    "    return x_cen, y_cen\n",
    "\n",
    "if rock_map.sum() > 0:\n",
    "    rock_xpix, rock_ypix = rover_coords(rock_map)\n",
    "\n",
    "    rock_xworld, rock_yworld = \\\n",
    "        pix_to_world(rock_xpix, rock_ypix, xpos, ypos, yaw, world_size, scale)\n",
    "\n",
    "    rock_xcen, rock_ycen = center_rock(rock_xpix, rock_ypix, rock_xworld, rock_yworld)\n",
    "\n",
    "    Rover.worldmap[rock_ycen, rock_xcen, 1] = 255\n",
    "    Rover.vision_image[:, :, 1] = rock_map * 255  # rock sample color-thresholded binary img\n",
    "\n",
    "    Rover.rockx = rock_xcen\n",
    "    Rover.rocky = rock_ycen\n",
    "    Rover.rock_angle = np.arctan2(rock_ycen, rock_xcen) * 180/np.pi\n",
    "    \n",
    "    # 11) Calculating the desired yaw angle to orient towards the rock\n",
    "    Rover.des_yaw = np.arctan2(ypos-rock_ycen, xpos-rock_xcen) * 180/np.pi\n",
    "    if 0 <= abs(Rover.des_yaw) <= 180:\n",
    "        Rover.des_yaw = 180 + Rover.des_yaw\n",
    "\n",
    "    # 12) Checking if any rock samples are not collected. \n",
    "    # If True, then the Rover goes to 'orient' mode\n",
    "    samples_uncollected = Rover.samples_located - Rover.samples_collected\n",
    "    if samples_uncollected > 0:\n",
    "        if Rover.orient_flag is 0 and not Rover.picking_up:\n",
    "            Rover.mode = 'orient'\n",
    "            Rover.orient_flag = 1\n",
    "\n",
    "else:\n",
    "    Rover.vision_image[:, :, 1] = 0  # if not found, mark it black\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Autonomous Navigation\n",
    "\n",
    "The `decision_step(Rover)` function in the `decision.py` script is used for navigating the Rover. \n",
    "\n",
    "### 4.1 Wrapper Functions for Rover navigation\n",
    "Certain wrapper functions are created for easier deployment of throttle, brakes, steering, and setting maximum velocities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# An average moving filter of steering angles\n",
    "def steerAverage(steer_list, steer, size=5):\n",
    "    if np.isnan(steer):\n",
    "        steer = 0\n",
    "    steer_list.append(steer)\n",
    "    if len(steer_list) > size:\n",
    "        steer_mean = sum(steer_list)/len(steer_list)\n",
    "        steer_list = steer_list.pop(0)      # remove first element\n",
    "        return steer_mean\n",
    "    else:\n",
    "        return steer\n",
    "\n",
    "# Applying brakes with a certain brake value\n",
    "def robotBrake(Rover, brake):\n",
    "    Rover.throttle = 0\n",
    "    Rover.brake = brake\n",
    "    Rover.steer = 0\n",
    "\n",
    "# Steering cw or ccw based on desired yaw angle\n",
    "def robotSteer(Rover, steer):\n",
    "    if Rover.yaw > Rover.des_yaw:\n",
    "        return -steer\n",
    "    else:\n",
    "        return steer\n",
    "\n",
    "# Throttling forward based on certain parameters\n",
    "def robotThrottle(Rover, max_vel, throttle=0.5, brake=0, steer=0):\n",
    "    Rover.max_vel = max_vel\n",
    "    if abs(Rover.vel) < abs(Rover.max_vel):\n",
    "        Rover.throttle = throttle\n",
    "    else:\n",
    "        Rover.throttle = 0\n",
    "    Rover.brake = brake\n",
    "    Rover.steer  = steer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Picking up rock sample\n",
    "\n",
    "A conditional is checked on every update if the Rover is near a rock sample or not. If it is, then it should pick up the rock sample and change `Rover.mode` to `forward` mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check if the sample is around. if so, then pick it up.\n",
    "if Rover.near_sample:\n",
    "    if Rover.vel > 0.5:     # If moving, then brake.\n",
    "        robotBrake(Rover, 5)\n",
    "        print (\">>> SAMPLE IS NEAR.\".format(Rover.brake))\n",
    "    Rover.throttle, Rover.steer = 0, 0\n",
    "\n",
    "    if not Rover.picking_up:    # Pick up sample. Go to forward mode\n",
    "        print (\">>> Picking up rock sample #{}\".format(Rover.samples_located))\n",
    "        Rover.send_pickup = True\n",
    "        Rover.max_vel = 3\n",
    "        Rover.mode = 'forward'\n",
    "        Rover.des_yaw = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Types of `Rover.mode`\n",
    "\n",
    "There are 4 modes that I am using for my Rover. They are: `orient, pickup, forward, stop`\n",
    "\n",
    "* `Orient Mode`: If a rock sample is detected, the Rover should stop and rotate towards the rock sample. Based on how much the orientation angle is going, the steering angle is determined. The steering angles are 3, 10, or 15 units. Once oriented, `Rover.mode` attribute changes to `pickup` mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Orient to face the rock sample\n",
    "if Rover.mode == 'orient':\n",
    "    if yawCheck:    #if facing sample, go to 'pickup' mode\n",
    "        Rover.mode = 'pickup'\n",
    "        printMode(Rover, note = 'orient', change=True)\n",
    "    else:   # If not facing sample, first stop, then orient\n",
    "        if Rover.vel > 0.5:  # If moving, then brake\n",
    "                robotBrake(Rover, 10)\n",
    "        else:\n",
    "            if abs(delta_yaw) >= 40:\n",
    "                Rover.steer = robotSteer(Rover, 15)\n",
    "            elif 10<= abs(delta_yaw) < 40:\n",
    "                Rover.steer = robotSteer(Rover, 10)\n",
    "            elif abs(delta_yaw) < 10:\n",
    "                Rover.steer = robotSteer(Rover, 3)\n",
    "            Rover.brake = 0\n",
    "            Rover.throttle = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Pickup Mode`: Once the Rover faces the rock sample, it should throttle towards it while maintaining the desired yaw angle. The chk1, chk2, chk3 variables are simply flags that let the Rover know if an obstacle is near in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Go near the rock\n",
    "elif Rover.mode == 'pickup':\n",
    "    chk1 = len(Rover.nav_angles) >= (Rover.stop_forward/16)  #close to the border\n",
    "    chk2 = len(Rover.nav_angles) >= (Rover.stop_forward/8)  #further from border\n",
    "    chk3 = len(Rover.nav_angles) >= (Rover.stop_forward/2)  #even further\n",
    "\n",
    "    if dist < 0.5 and chk3: # if within certain distance of rock, first stop, then steer\n",
    "        print (\"Very close to rock but plenty of room ahead -> {}\".format(len(Rover.nav_angles)))\n",
    "        if Rover.vel > 0.25:\n",
    "            robotBrake(Rover, 5)\n",
    "        else:\n",
    "            robotThrottle(Rover, 1, throttle=0, steer = 15)\n",
    "    elif dist < 0.8 and chk2:     # if close to rock and border near\n",
    "        print (\"Close to rock but little room ahead - > {}\".format(len(Rover.nav_angles)))\n",
    "        if Rover.vel > 0.25:\n",
    "            robotBrake(Rover, 5)\n",
    "        else:\n",
    "            robotThrottle(Rover, 1, throttle=0, steer = 15)\n",
    "    elif  -3 <= delta_yaw <= 3:  # if facing sample, drive straight to it\n",
    "        print (\"going straight\")\n",
    "        robotThrottle(Rover, 1.5, throttle=1)\n",
    "    else:   # if not near and not facing sample, drive and steer towards it\n",
    "        print (\"steering\")\n",
    "        if delta_yaw >0:\n",
    "            robotThrottle(Rover, 1, throttle=0.5, steer = -5)\n",
    "        else:\n",
    "            robotThrottle(Rover, 1, throttle=0.5, steer = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Forward Mode`: Navigate the terrain based on the angle computed from average navigable vector. If there is no navigable terrain ahead, then change to 'stop' mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if Rover.mode == 'forward':\n",
    "    if Rover.samples_located > 0 and uncollected is 0:\n",
    "        Rover.orient_flag = 0\n",
    "        \n",
    "    steer_old = np.clip(np.mean(Rover.nav_angles*180 / np.pi), -15, 15)\n",
    "    steer = steerAverage(Rover.steer_list, steer_old, size=3)\n",
    "    \n",
    "    if len(Rover.nav_angles) >= Rover.stop_forward:\n",
    "        robotThrottle(Rover, 4, 1.5, steer = steer)\n",
    "    elif len(Rover.nav_angles) < Rover.stop_forward:\n",
    "        robotBrake(Rover, 15)\n",
    "        Rover.mode = 'stop'\n",
    "        printMode(Rover, 'forward', change=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Stop Mode`: If there are no navigable pixels ahead, then steer clockwise until navigable pixels detected and change the mode back to `forward` mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check if the sample is around. if so, then pick it up.\n",
    "if Rover.near_sample:\n",
    "    if Rover.vel > 0.5:     # If moving, then brake.\n",
    "        robotBrake(Rover, 5)\n",
    "        print (\">>> SAMPLE IS NEAR.\".format(Rover.brake))\n",
    "    Rover.throttle, Rover.steer = 0, 0\n",
    "\n",
    "    if not Rover.picking_up:    # Pick up sample. Go to forward mode\n",
    "        print (\">>> Picking up rock sample #{}\".format(Rover.samples_located))\n",
    "        Rover.send_pickup = True\n",
    "        Rover.max_vel = 3\n",
    "        Rover.mode = 'forward'\n",
    "        Rover.des_yaw = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Worldmap and Vision Image:\n",
    "\n",
    "The vision_image and worldmap are shown on the left and right of the screen.\n",
    "\n",
    "### 5.1 Vision image\n",
    "If a rock sample is detected, it is shown in green color. The navigable terrain is colored in blue whereas the obstacle outlining this navigable terrain is marked in red. A sample image is shown below\n",
    "\n",
    "[vision_rock]: vision_rock.png\n",
    "![alt text][vision_rock]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Worldmap image\n",
    "The worldmap contains some statistics on the Rover such as time elapsed, percentage of the terrain mapped, and fidelity. Apart from stats, the navigable terrain, obstacles, and rocks are highlighted in the map.\n",
    "\n",
    "I have added additional stats and labels to the worldmap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Rover's location and orientation`: The position and orientation of the Rover is shown on the worldmap as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting rover's location on the worldmap\n",
    "rov_x = int (Rover.pos[0])\n",
    "rov_y = int (Rover.pos[1])\n",
    "rover_size = 3\n",
    "map_add[rov_y - rover_size:rov_y + rover_size, \\\n",
    "          rov_x - rover_size:rov_x + rover_size, 0] = 255\n",
    "\n",
    "# Drawing an arrow coming out of the rover\n",
    "length = 30\n",
    "arrow_x =  int (rov_x + length * np.cos(Rover.yaw * np.pi / 180.0))\n",
    "arrow_y =  int (rov_y + length * np.sin(Rover.yaw * np.pi / 180.0))\n",
    "cv2.line(map_add, (rov_x+2,rov_y+2), (arrow_x,arrow_y), (255,0,0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Grids`: The ground truth of the navigable region is divided into equally spaced grids of 10x10 pixels each. This lets the Rover know it is currently in which grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# worldmap divided into equally spaced grids\n",
    "checkBlacks = map_add[:,:,:] < 10\n",
    "size = 10\n",
    "for i in range(0,199,size):\n",
    "    cv2.line(map_add, (i, 0), (i, 199), (255,255,255), 1)\n",
    "    cv2.line(map_add, (0, i), (199, i), (255,255,255), 1)\n",
    "map_add[checkBlacks] = 0\n",
    "grid_x, grid_y = getGrid(Rover.pos[0], Rover.pos[1], size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample of the worldmap is shown below.\n",
    "\n",
    "[worldmap]: worldmap.png\n",
    "![alt text][worldmap]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": false
    }
   },
   "source": [
    "## 6. Improvements\n",
    "\n",
    "### 6.1 Increased fidelity\n",
    "I would like to work on increasing the fidelity of my Rover. Currently, I am averaging around 70% after masking my warped navigable terrain. Prior to this, my fidelity would average around 55% only.\n",
    "\n",
    "### 6.2 Returning to home position with all 6 samples\n",
    "Currently, the Rover is only able to collect all 6 samples but I did not implement any logic for the Rover to return to its initial place. This is something I would like to work on.\n",
    "\n",
    "### 6.3 Avoid re-visiting terrains\n",
    "In order to tackle this, I had created grids in the worldmap for the Rover to localize itself into grid cells. As the Rover is entering a new grid, each grid gets updated with a weight. However, I have not implemented any algorithm after this for the Rover to unnecessarily visit certain terrains. An example of the grid generated is shown below. It is a 20x20 matrix.\n",
    "\n",
    "[grid_map]: grid_map.png\n",
    "![alt text][grid_map]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python [conda env:RoboND]",
   "language": "python",
   "name": "conda-env-RoboND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
